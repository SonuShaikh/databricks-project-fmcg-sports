{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63bf13b3-04c3-4cc8-bfbe-2bb41b9118a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "import logging\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('fmcg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a95364-dc10-472d-8667-175a7f04e53e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/apache-spark/databricks-project-fmcg-sports/utils/utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8cf72e4-e8f5-4741-ac97-a3fe78d460bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read customer data\n",
    "file_path = f'{s3_bucket}/{data_source}/customers.csv'\n",
    "df_cust_bronze = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header','true')\n",
    "    .option('inferSchema','true')\n",
    "    .load(file_path)\n",
    ")\n",
    "\n",
    "df_cust_bronze.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17124fcc-4be4-4d16-927a-4604cb47235b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### As I see following issue with imported data\n",
    "0. duplicate records\n",
    "1. customer id is intiger it should be string, \n",
    "2. customer_name is not consistent it has leeding spaces, capatilisaiton etc\n",
    "3. city name has speling mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65aff42a-ed4d-4060-aab8-00b05070247b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "# check if there any duplicate\n",
    "df_cust_bronze.groupBy('customer_id').count().filter(f.col('count') > 1).display()\n",
    "\n",
    "# remove these duplicates\n",
    "df_cust_silver = df_cust_bronze.dropDuplicates(['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41c03a1b-7d77-41c6-a971-14e804945daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a city mapping df to join with original df\n",
    "df_city = spark.createDataFrame(clean_city, [\"city\", \"clean_city\"])\n",
    "\n",
    "# join both table and get city and trim the first name\n",
    "df_cust_silver = (\n",
    "    df_cust_silver\n",
    "    .join(df_city, on=\"city\", how='left')\n",
    "    .select(\"customer_id\", \"customer_name\", f.col('clean_city').alias('city'))\n",
    ").withColumns({\n",
    "    'customer_name': f.initcap(f.trim(f.col('customer_name')))\n",
    "})\n",
    "df_cust_silver.select('city').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c81d332-5e8c-451e-97b9-9de233a0180c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We see there are few null value in city, If we check other record customer name it has multiple cities. \n",
    "df_cust_silver.filter(f.col(\"city\").isNull()).show()\n",
    "df_cust_silver.join(\n",
    "    df_cust_silver.filter(f.col(\"city\").isNull()),\n",
    "    on=\"customer_name\",\n",
    "    how='inner'\n",
    ")#.display()\n",
    "\n",
    "df_cust_silver.filter(f.col(\"customer_name\").isin(\n",
    "    df_cust_silver.filter(f.col(\"city\").isNull()).select('customer_name')\n",
    "    )\n",
    ").orderBy(\"customer_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1f7353a-0f4f-40f8-b58f-61cfcbab28e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# here is infor of missing city of customers\n",
    "missing_city = {\n",
    "    '789521':'Bengalore',\n",
    "    '789603':'Hyderabad',\n",
    "    '789521':'New Delhi',\n",
    "    '789403':'Hyderabad',\n",
    "    '789420':'New Delhi'\n",
    "}\n",
    "\n",
    "# create a dataframe of missing cities\n",
    "\n",
    "df_missing_city = spark.createDataFrame(\n",
    "    [(k, v) for k, v in missing_city.items()],\n",
    "    ['customer_id', 'fixed_city']\n",
    ")\n",
    "\n",
    "#df_missing_city.display()\n",
    "# Join table and update null values with fixed city data\n",
    "df_cust_silver = df_cust_silver.join(\n",
    "    df_missing_city, on='customer_id', how='left'\n",
    ").withColumn(\n",
    "    'city', f.coalesce(f.col(\"city\"), f.col('fixed_city'))\n",
    ").drop('fixed_city')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5344dd3-f81b-4beb-9ff8-c0be100823b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# last the customer id is integer need to change it to string. \n",
    "# and this table has city with customer name so it is better merge them - \n",
    "# and gold schema has three additional column so we have to add them as well\n",
    "# market - India, platform - Sport Bar, channel - Acquisition \n",
    "\n",
    "df_cust_silver = df_cust_silver.withColumns({\n",
    "    'customer_name': f.concat_ws(' - ', f.col('customer_name'), f.coalesce(f.col(\"city\"), f.lit('Unknown'))),\n",
    "    'customer_id': f.col(\"customer_id\").cast(\"string\"),\n",
    "    'market': f.lit('India'),\n",
    "    'platform': f.lit('Sport Bar'),\n",
    "    'channel': f.lit('Acquisition')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "371d900e-8a1b-4635-a60a-5d62f550f646",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save data to silver layer\n",
    "df_cust_silver.write\\\n",
    "    .format('delta')\\\n",
    "    .option('delta.enableChangeDataFeed','true')\\\n",
    "    .option('mergeSchema','true')\\\n",
    "    .mode('overwrite')\\\n",
    "    .saveAsTable(f'{catalog}.{silver_schema}.{data_source}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0401509-cd14-4785-af91-4ebeaaceb98b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM fmcg.silver.customers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb628c4-e258-4bd4-ae2a-16486fa7b642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# There are not further transformation required for this table need to save this to gold layer\n",
    "df_cust_silver.write\\\n",
    "    .format('delta')\\\n",
    "    .option('mergeSchema','true')\\\n",
    "    .mode('overwrite')\\\n",
    "    .saveAsTable(f'{catalog}.{gold_schema}.sp_dim_{data_source}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "370c12aa-3b50-4204-9f31-16cff476ac31",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "#Let's merge the both table now\n",
    "# Target table must be delta table\n",
    "parent_cust      = DeltaTable.forName(spark, 'fmcg.gold.dim_customers')\n",
    "child_cust_table = spark.sql('SELECT * FROM fmcg.gold.sp_dim_customers').select(\n",
    "    f.col('customer_id').alias('customer_code'),\n",
    "    f.col('customer_name').alias('customer'),\n",
    "    'city',\n",
    "    'market',\n",
    "    'platform',\n",
    "    'channel'\n",
    ")\n",
    "\n",
    "parent_cust.alias('p').merge(\n",
    "    source=child_cust_table.alias('c'),\n",
    "    condition='p.customer_code = c.customer_code',\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae05654a-9d3b-421e-9d64-bf84c5549010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(f'{catalog}.{gold_schema}.dim_customers').groupBy('platform').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68e8a159-a290-4e76-b7d0-e36c88df72b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4775636958078350,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_customer_data_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
